{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ready_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "\n",
    "    tokenized_text = TreebankWordTokenizer().tokenize(text)\n",
    "    \n",
    "    wordsFiltered = []\n",
    "\n",
    "    for w in tokenized_text:\n",
    "        for wf in re.findall(r'(?u)(\\w+)', w):\n",
    "            #for wfreal in re.findall(r'(\\D+)', wf):\n",
    "            wordsFiltered.append(''.join(wf))\n",
    "    \n",
    "    return wordsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_context(file_path):\n",
    "    \n",
    "    with open(file_path) as fl:\n",
    "        try:\n",
    "            text = fl.read()\n",
    "        except:\n",
    "            print (\"Error: \" + file_path )\n",
    "    \n",
    "    reg_term = re.compile(r'&(.*?)!&')\n",
    "    indexes = []\n",
    "    for i in reg_term.finditer(text):\n",
    "        indexes.append((i.start(), i.end()))\n",
    "\n",
    "    left_context = []\n",
    "    right_context = []\n",
    "    left_word = []\n",
    "\n",
    "    for ind in indexes:\n",
    "        left_part = text[:ind[0]]\n",
    "        right_part = text[ind[1]+1:]\n",
    "        clear_left = preprocess(left_part)\n",
    "        clear_right = preprocess(right_part)\n",
    "    \n",
    "    \n",
    "        #left context\n",
    "        if len(clear_left) > 5:\n",
    "            left_context.append(clear_left[-5:])\n",
    "            left_word.append(clear_left[-1])\n",
    "        else:\n",
    "            left_context.append(clear_left)\n",
    "            if len(clear_left) > 0:\n",
    "                left_word.append(clear_left[-1])\n",
    "            else:\n",
    "                left_word.append(' ')\n",
    "    \n",
    "        #right context\n",
    "        if len(clear_right) > 5:\n",
    "            right_context.append(clear_right[:5])\n",
    "        else:\n",
    "            right_context.append(clear_right)\n",
    "            \n",
    "    \n",
    "    terms = reg_term.findall(text)\n",
    "    \n",
    "    global ready_df\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    \n",
    "    for i in range(len(terms)):\n",
    "        lft = left_context[i]\n",
    "        lw = str(left_word[i])\n",
    "        term = terms[i]\n",
    "        rgt = right_context[i]\n",
    "        lc = ' '.join(lft)\n",
    "        rc = ' '.join(rgt)\n",
    "        \n",
    "        df = pd.DataFrame([[lc, lw, term, rc]],\n",
    "                      columns=['left_context', 'left_word', 'term', 'right_context'])\n",
    "        ready_df = ready_df.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_path = './terms_markup/Marked/'\n",
    "\n",
    "for path, dirs, files in os.walk(start_path):\n",
    "\n",
    "    for fname in files:\n",
    "        if not fname.startswith('.'):\n",
    "            get_context(start_path+fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2266"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ready_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready_df.tail(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sorted = ready_df.sort_values(['left_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_context</th>\n",
       "      <th>left_word</th>\n",
       "      <th>term</th>\n",
       "      <th>right_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>силой противящейся движению поезда</td>\n",
       "      <td>является</td>\n",
       "      <td>аэродинамическое сопротивление</td>\n",
       "      <td>Предыдущий рекорд скорости был установлен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>огромной опорой именно на язык</td>\n",
       "      <td>язык</td>\n",
       "      <td>эмоциональной рефлексии</td>\n",
       "      <td>об этом пишет польско австралийский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>огромной опорой именно на</td>\n",
       "      <td>язык</td>\n",
       "      <td>эмоциональной рефлексии</td>\n",
       "      <td>об этом пишет польско австралийский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>на так называемые внешнеполинезийские языки</td>\n",
       "      <td>языки</td>\n",
       "      <td>носители</td>\n",
       "      <td>которых живут за пределами Полинезийского</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>на так называемые внешнеполинезийские</td>\n",
       "      <td>языки</td>\n",
       "      <td>носители</td>\n",
       "      <td>которых живут за пределами Полинезийского</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  left_context left_word  \\\n",
       "0           силой противящейся движению поезда  является   \n",
       "0               огромной опорой именно на язык      язык   \n",
       "0                    огромной опорой именно на      язык   \n",
       "0  на так называемые внешнеполинезийские языки     языки   \n",
       "0        на так называемые внешнеполинезийские     языки   \n",
       "\n",
       "                             term                              right_context  \n",
       "0  аэродинамическое сопротивление  Предыдущий рекорд скорости был установлен  \n",
       "0         эмоциональной рефлексии        об этом пишет польско австралийский  \n",
       "0         эмоциональной рефлексии        об этом пишет польско австралийский  \n",
       "0                        носители  которых живут за пределами Полинезийского  \n",
       "0                        носители  которых живут за пределами Полинезийского  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ready_df.to_csv('terms_context.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv('terms_sorted.csv', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
