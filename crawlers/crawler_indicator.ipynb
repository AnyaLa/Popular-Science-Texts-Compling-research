{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Краулер для Indicator.ru ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем все необходимые методы для последующей работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем пустой датафрейм. Он пригодится нам в дальнейшем для сортировки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ready_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cкачиваем страницы ##\n",
    "Функция для скачивания контента по ссылке в виде файла. Аргумент функции - ссылка. Результат работы кода функции - файл в директории \"Pages\".\n",
    "Уникальное имя файла генерируется за счет части url (на основе анализа ссылок на статьи в Indicator.ru) за счет замены / на _ и отсекания общей части для всех url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download(url):\n",
    "    source = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "    file_name = url.split('https://indicator.ru/article/')[1].replace('/','_')\n",
    "    fl = open('pages_indicator/' + file_name, 'w')\n",
    "    fl.write(str(source))\n",
    "    fl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Записываем тексты статей в отдельные файлы ##\n",
    "\n",
    "Функция принимает в качестве аргумента текст и имя файла для записи (папка clear_text создана заранее). Данная функция понадобится нам в следующей функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_clear_text(text, file_name):\n",
    "    f = open('clear_text_indicator/'+file_name + '.txt', 'w')\n",
    "    f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чистим текст, размечаем данные ##\n",
    "    Функция принимает на вход путь к файлу (из ранее сгенерированной директории \"Pages\"). При помощи библиотеки Beautiful Soup на основании предварительного анализа структуры статей сайта находим элементы статьи: \n",
    "    - путь до текстового файла на Яндекс-диске\n",
    "    - источник\n",
    "    - url\n",
    "    - дату (дату берем из ссылки на статью при помощи регулярных выражений)\n",
    "    - заголовок\n",
    "    - подзаголовок\n",
    "    - автор (позаголовка и автора может не быть, поэтому в случае их отсутствия пишем None)\n",
    "    - рубрика\n",
    "    - тэги\n",
    "    - жанр\n",
    "    \n",
    "    Полученные данные добавляем в заранее заготовленный пустой датафрейм; каждая колонка соответсвует вышеперечисленным элементам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear(file_path):\n",
    "    global ready_df #связывает локальную переменную в коде функции с глобальной переменной в общем коде (задали в начале кода)\n",
    "    with open(file_path) as fl:\n",
    "        source = fl.read()\n",
    "    \n",
    "    soup_article = bs.BeautifulSoup(source, 'lxml')\n",
    "    \n",
    "    clear_p = ''    \n",
    "    for paragraph in soup_article.find_all('div', class_ = 'article__body js-article-body'):\n",
    "        clear_p = clear_p + paragraph.text\n",
    "    \n",
    "    head_title = soup_article.find('div', class_='headline__title').text\n",
    "\n",
    "    rubric = soup_article.find('div', class_= 'headline__part').text\n",
    "\n",
    "    date_raw = re.search(r'.*([0-9]{4}_[0-9]{2}_[0-9]{2}).*', file_path)\n",
    "    date = date_raw.group(1)\n",
    "\n",
    "    subtitle_raw = soup_article.find('div', class_ = 'headline__subtitle')\n",
    "    if subtitle_raw == None:\n",
    "        subtitle = 'None'\n",
    "    else:\n",
    "        subtitle = subtitle_raw.text\n",
    "    \n",
    "    author_raw = soup_article.find('div', class_ = 'article__author')\n",
    "    if author_raw == None:\n",
    "        author = ''\n",
    "    else:\n",
    "        author = author_raw.text.replace('Автор:','').strip()\n",
    "        \n",
    "    genre = 'Статьи'\n",
    "    tags = ''\n",
    "    path = file_path.replace('./pages_indicator', '/indicator_clear_text')\n",
    "    site = 'indicator.ru'\n",
    "    f_name = file_path.replace('pages_indicator/','')\n",
    "    name = f_name.replace('./', '')\n",
    "    url = 'https://indicator.ru/article/' + name.replace('_','/')\n",
    "    \n",
    "    \n",
    "    #print('Path: %s, name: %s'%(path, name))\n",
    "    df = pd.DataFrame([[path, site, url, date, head_title, subtitle, author, rubric, tags, genre]],\n",
    "                      columns=['path', 'source', 'url', 'date','title','subtitle','author','rubrics','tags', 'genre'])\n",
    "    ready_df = ready_df.append(df)\n",
    "    save_clear_text(clear_p, name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Код ##\n",
    "\n",
    "   К адресу сайта indicator.ru добавляем robots.txt => находим https://indicator.ru/sitemap.xml => находим все ссылки на статьи https://indicator.ru/sitemap-articles.xml.\n",
    "   При помощи Beuatiful Soup выделяем адреса ссылок.\n",
    "   Циклом при помощи написанной выше функции скачивания проходим по всем ссылкам статей и скачиваем их в папку \"Pages\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sitemap_articles = urllib.request.urlopen('https://indicator.ru/sitemap-articles.xml').read()\n",
    "soup_links = bs.BeautifulSoup(sitemap_articles, 'lxml')\n",
    "\n",
    "for article_url in  soup_links.find_all('loc'):\n",
    "    download(article_url.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходим по скачанным файлам в папке \"Pages_indicator\", отсеиваем служебные, остальные файлы чистим ранее написанной функцией clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_path = './pages_indicator/'\n",
    "\n",
    "for path, dirs, files in os.walk(start_path):\n",
    "\n",
    "    for fname in files:\n",
    "        if not fname.startswith('.'):\n",
    "            clear(start_path+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pages_indicator/2017_01_04_chem-klimatologam-...</td>\n",
       "      <td>indicator.ru</td>\n",
       "      <td>https://indicator.ru/article/2017/01/04/chem-k...</td>\n",
       "      <td>2017_01_04</td>\n",
       "      <td>Плюсы, минусы, коралловые рифы</td>\n",
       "      <td>Чем климатологам запомнился 2016 год</td>\n",
       "      <td>Дарья Сапрыкина</td>\n",
       "      <td>Науки о Земле</td>\n",
       "      <td></td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pages_indicator/2017_05_22_patent-na-pianolu_</td>\n",
       "      <td>indicator.ru</td>\n",
       "      <td>https://indicator.ru/article/2017/05/22/patent...</td>\n",
       "      <td>2017_05_22</td>\n",
       "      <td>История науки: окончательный рассказ о механич...</td>\n",
       "      <td>117 лет назад был выдан патент на пианолу</td>\n",
       "      <td></td>\n",
       "      <td>Технические науки</td>\n",
       "      <td></td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pages_indicator/2016_09_30_boeing_</td>\n",
       "      <td>indicator.ru</td>\n",
       "      <td>https://indicator.ru/article/2016/09/30/boeing/</td>\n",
       "      <td>2016_09_30</td>\n",
       "      <td>История науки: мечта в металлическом корпусе</td>\n",
       "      <td>135 лет назад родился основатель фирмы «Боинг»</td>\n",
       "      <td>Алёна Манузина</td>\n",
       "      <td>Технические науки</td>\n",
       "      <td></td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pages_indicator/2017_08_09_bibliometriya-ot-m...</td>\n",
       "      <td>indicator.ru</td>\n",
       "      <td>https://indicator.ru/article/2017/08/09/biblio...</td>\n",
       "      <td>2017_08_09</td>\n",
       "      <td>Наука подобрать: помогает ли наукометрия прини...</td>\n",
       "      <td>Астроном Майкл Курц о том, как использовать на...</td>\n",
       "      <td></td>\n",
       "      <td>Астрономия</td>\n",
       "      <td></td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pages_indicator/2017_03_18_tri-v-odnom-lekars...</td>\n",
       "      <td>indicator.ru</td>\n",
       "      <td>https://indicator.ru/article/2017/03/18/tri-v-...</td>\n",
       "      <td>2017_03_18</td>\n",
       "      <td>Три в одном: лекарства, ДНК и магниторецепция....</td>\n",
       "      <td>Трансляция биологического лектория Indicator.R...</td>\n",
       "      <td></td>\n",
       "      <td>Биология</td>\n",
       "      <td></td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path        source  \\\n",
       "0  /pages_indicator/2017_01_04_chem-klimatologam-...  indicator.ru   \n",
       "0     /pages_indicator/2017_05_22_patent-na-pianolu_  indicator.ru   \n",
       "0                /pages_indicator/2016_09_30_boeing_  indicator.ru   \n",
       "0  /pages_indicator/2017_08_09_bibliometriya-ot-m...  indicator.ru   \n",
       "0  /pages_indicator/2017_03_18_tri-v-odnom-lekars...  indicator.ru   \n",
       "\n",
       "                                                 url        date  \\\n",
       "0  https://indicator.ru/article/2017/01/04/chem-k...  2017_01_04   \n",
       "0  https://indicator.ru/article/2017/05/22/patent...  2017_05_22   \n",
       "0    https://indicator.ru/article/2016/09/30/boeing/  2016_09_30   \n",
       "0  https://indicator.ru/article/2017/08/09/biblio...  2017_08_09   \n",
       "0  https://indicator.ru/article/2017/03/18/tri-v-...  2017_03_18   \n",
       "\n",
       "                                               title  \\\n",
       "0                     Плюсы, минусы, коралловые рифы   \n",
       "0  История науки: окончательный рассказ о механич...   \n",
       "0       История науки: мечта в металлическом корпусе   \n",
       "0  Наука подобрать: помогает ли наукометрия прини...   \n",
       "0  Три в одном: лекарства, ДНК и магниторецепция....   \n",
       "\n",
       "                                            subtitle           author  \\\n",
       "0               Чем климатологам запомнился 2016 год  Дарья Сапрыкина   \n",
       "0          117 лет назад был выдан патент на пианолу                    \n",
       "0     135 лет назад родился основатель фирмы «Боинг»   Алёна Манузина   \n",
       "0  Астроном Майкл Курц о том, как использовать на...                    \n",
       "0  Трансляция биологического лектория Indicator.R...                    \n",
       "\n",
       "             rubrics tags   genre  \n",
       "0      Науки о Земле       Статьи  \n",
       "0  Технические науки       Статьи  \n",
       "0  Технические науки       Статьи  \n",
       "0         Астрономия       Статьи  \n",
       "0           Биология       Статьи  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем полученный датафрейм в отдельный файл формата csv (comma separated values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ready_df.to_csv('indicator.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
