{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мета-информация в отдельной таблице:\n",
    "\n",
    "    1 колонка - путь к файлу\n",
    "    2 колонка - ресурс\n",
    "    3 колонка - дата\n",
    "    4 колонка - заголовок\n",
    "    5 колонка - подзаголовок\n",
    "    6 колонка - автор\n",
    "    7 колонка - рубрика\n",
    "    8 колонка - тэги(?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = ['path', 'source', 'url', 'date', 'title', 'subtitle', 'author', 'rubrics', 'tags', 'genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nplus1 Parsing BeautifulSoup #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_metadata_nplus1(file_paths: list, yandex_disk_names: list):\n",
    "    ready_df = pd.DataFrame(columns=column_names)\n",
    "    directory_index = '/home/nst/mount/data/linguistics_hse/popular-science-research/popular-science-repo/'\n",
    "    \n",
    "    #pbar = tqdm(total=len(file_paths))\n",
    "    #pbar = tqdm(total=100)\n",
    "    \n",
    "# Iterate through file_path, yd_name\n",
    "    iterable = zip(file_paths, yandex_disk_names)\n",
    "    \n",
    "    for file_path, yandex_disk_name in tqdm(iterable):\n",
    "       # pbar.update(100)\n",
    "        row = []\n",
    "        \n",
    "        directory = directory_index + file_path.rstrip()\n",
    "        \n",
    "# Open text from source file\n",
    "        with open(directory) as file_:\n",
    "            source = file_.read()\n",
    "            \n",
    "    # Compile path\n",
    "        path_index_yd = 'nplus1.ru/nplus1_blog/'\n",
    "        path = path_index_yd + yandex_disk_name\n",
    "        row.append(path)\n",
    "        \n",
    "    # Add source\n",
    "        web_source = 'nplus1.ru'\n",
    "        row.append(web_source)\n",
    "\n",
    "    # Compile url \n",
    "        re_link = re.compile('data\\/(.*)\\.html')\n",
    "        link = re_link.findall(file_path)\n",
    "        link = ''.join(link) \n",
    "        row.append(link)\n",
    "\n",
    "        \n",
    "        \n",
    "        soup_article = BeautifulSoup(source, 'html.parser')\n",
    "        \n",
    "    # Find date\n",
    "        raw_date = soup_article.find(attrs={'itemprop': 'datePublished'})['content']\n",
    "        row.append(raw_date)\n",
    "        \n",
    "\n",
    "    # Find a title\n",
    "        try:\n",
    "\n",
    "            head_title = soup_article.find('h1').text.strip()\n",
    "            \n",
    "        except AttributeError:\n",
    "            head_title = ''\n",
    "        \n",
    "        row.append(head_title)\n",
    "        \n",
    "    # Add subtitle        \n",
    "        subtitle = ''\n",
    "        row.append(subtitle)\n",
    "\n",
    "    # Find an author\n",
    "        try:\n",
    "\n",
    "            re_author = re.compile('[A-Za-z]')\n",
    "            author = soup_article.find(attrs={'name': 'mediator_author'})['content']\n",
    "            if re_author.match(author):\n",
    "                author = ''\n",
    "       # author = ''\n",
    "        except TypeError:\n",
    "            author = ''\n",
    "        \n",
    "        row.append(author)\n",
    "        \n",
    "    # Find rubrics\n",
    "        try:\n",
    "            broad_rubrics = soup_article.find('p', class_='table').text \n",
    "            broad_rubrics = broad_rubrics.split('\\n')\n",
    "            broad_rubrics = '_'.join(broad_rubrics)\n",
    "        except AttributeError:\n",
    "            broad_rubrics = ''\n",
    "        row.append(broad_rubrics)\n",
    "        \n",
    "    # Add tags\n",
    "        rubrics = ''\n",
    "        row.append(rubrics)\n",
    "\n",
    "    # Add genre\n",
    "        genre = 'Блоги'\n",
    "        row.append(genre)\n",
    "\n",
    "    # Compile data frame\n",
    "        ready_df = ready_df.append(pd.Series(row, index=column_names), ignore_index=True)\n",
    "        \n",
    "        #pbar.close()\n",
    "    return ready_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nplus1 news #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read through indices\n",
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/popular-science-repo/nplus1_news_index.txt') as ps_index:\n",
    "    read_index = ps_index.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read through file names on YandexDisk\n",
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/crawlers/nplus1/yd_news.txt', 'r') as yd_n:\n",
    "    yd_index = yd_n.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read-index: 11170 \n",
      "yd_index: 11170\n"
     ]
    }
   ],
   "source": [
    "print('read-index:', len(read_index), '\\nyd_index:', len(yd_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985f27f15ef54fada01f4c5965996472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_nplus1_news = parse_metadata_nplus1(read_index, yd_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nplus1.ru/nplus1_news/nplus1.ru-news-2015-03-0...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/news/2015/03/02/bionics</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>Травму нервного плечевого сплетения научились ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>_Наука_Разное_</td>\n",
       "      <td></td>\n",
       "      <td>Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nplus1.ru/nplus1_news/nplus1.ru-news-2015-03-0...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/news/2015/03/02/blackhole</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>Рекордно молодая сверхмассивная дыра удивила ф...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>_Космос_Наука_Разное_</td>\n",
       "      <td></td>\n",
       "      <td>Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nplus1.ru/nplus1_news/nplus1.ru-news-2015-03-0...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/news/2015/03/02/chaotic</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>Физики поделили экономики на «ламинарные» и «х...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>_Наука_Физики смогли_</td>\n",
       "      <td></td>\n",
       "      <td>Новости</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     source  \\\n",
       "0  nplus1.ru/nplus1_news/nplus1.ru-news-2015-03-0...  nplus1.ru   \n",
       "1  nplus1.ru/nplus1_news/nplus1.ru-news-2015-03-0...  nplus1.ru   \n",
       "2  nplus1.ru/nplus1_news/nplus1.ru-news-2015-03-0...  nplus1.ru   \n",
       "\n",
       "                                   url        date  \\\n",
       "0    nplus1.ru/news/2015/03/02/bionics  2015-03-02   \n",
       "1  nplus1.ru/news/2015/03/02/blackhole  2015-03-02   \n",
       "2    nplus1.ru/news/2015/03/02/chaotic  2015-03-02   \n",
       "\n",
       "                                               title subtitle author  \\\n",
       "0  Травму нервного плечевого сплетения научились ...                   \n",
       "1  Рекордно молодая сверхмассивная дыра удивила ф...                   \n",
       "2  Физики поделили экономики на «ламинарные» и «х...                   \n",
       "\n",
       "                 rubrics tags    genre  \n",
       "0         _Наука_Разное_       Новости  \n",
       "1  _Космос_Наука_Разное_       Новости  \n",
       "2  _Наука_Физики смогли_       Новости  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nplus1_news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bd4c1615db4e6fa2db21494141e259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_rubrics = []\n",
    "rubrics_list = df_nplus1_news['rubrics'].values\n",
    "rubrics_list = rubrics_list.tolist()\n",
    "for line in tqdm(rubrics_list):\n",
    "    split_rubrics = line.split('_')\n",
    "    split_rubrics = split_rubrics[1:-1]\n",
    "    unique_rubrics.extend(split_rubrics)\n",
    "unique_rubrics = set(unique_rubrics)\n",
    "unique_rubrics = '\\n'.join(unique_rubrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nplus1_news_rubric_list.txt', 'w') as fl:\n",
    "    fl.write(unique_rubrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_nplus1_news_csv = df_nplus1_news.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nplus1_news.csv', 'w') as fl:\n",
    "    fl.write(df_nplus1_news_csv)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nplus1 materials #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/popular-science-repo/nplus1_material_index.txt') as ps_index:\n",
    "    read_index = ps_index.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read through file names on YandexDisk\n",
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/crawlers/nplus1/yd_materials.txt', 'r') as yd_n:\n",
    "    yd_index = yd_n.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read-index: 536 \n",
      "yd_index: 536\n"
     ]
    }
   ],
   "source": [
    "print('read-index:', len(read_index), '\\nyd_index:', len(yd_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7443aa21a9ed4cb4b4c3260106838979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_nplus1_materials = parse_metadata_nplus1(read_index, yd_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nplus1.ru/nplus1_materials/nplus1.ru-material-...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/material/2015/04/10/waranimals</td>\n",
       "      <td>2015-04-10</td>\n",
       "      <td>Вы звери, господа</td>\n",
       "      <td></td>\n",
       "      <td>Александр Ершов</td>\n",
       "      <td>_Наука_Археология_</td>\n",
       "      <td></td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nplus1.ru/nplus1_materials/nplus1.ru-material-...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/material/2015/04/11/greencloud</td>\n",
       "      <td>2015-04-11</td>\n",
       "      <td>Зеленые рукава галактик</td>\n",
       "      <td></td>\n",
       "      <td>Владимир Королев</td>\n",
       "      <td>_Космос_</td>\n",
       "      <td></td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nplus1.ru/nplus1_materials/nplus1.ru-material-...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/material/2015/04/11/seasontwo</td>\n",
       "      <td>2015-04-11</td>\n",
       "      <td>Коллайдер: Перезагрузка</td>\n",
       "      <td></td>\n",
       "      <td>Александр Ершов</td>\n",
       "      <td>_Наука_Второй сезон Коллайдера_</td>\n",
       "      <td></td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     source  \\\n",
       "0  nplus1.ru/nplus1_materials/nplus1.ru-material-...  nplus1.ru   \n",
       "1  nplus1.ru/nplus1_materials/nplus1.ru-material-...  nplus1.ru   \n",
       "2  nplus1.ru/nplus1_materials/nplus1.ru-material-...  nplus1.ru   \n",
       "\n",
       "                                        url        date  \\\n",
       "0  nplus1.ru/material/2015/04/10/waranimals  2015-04-10   \n",
       "1  nplus1.ru/material/2015/04/11/greencloud  2015-04-11   \n",
       "2   nplus1.ru/material/2015/04/11/seasontwo  2015-04-11   \n",
       "\n",
       "                     title subtitle            author  \\\n",
       "0        Вы звери, господа            Александр Ершов   \n",
       "1  Зеленые рукава галактик           Владимир Королев   \n",
       "2  Коллайдер: Перезагрузка            Александр Ершов   \n",
       "\n",
       "                           rubrics tags   genre  \n",
       "0               _Наука_Археология_       Статьи  \n",
       "1                         _Космос_       Статьи  \n",
       "2  _Наука_Второй сезон Коллайдера_       Статьи  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nplus1_materials.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c592e551f18b4a709f9ce3b1e493e78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_rubrics = []\n",
    "rubrics_list = df_nplus1_materials['rubrics'].values\n",
    "rubrics_list = rubrics_list.tolist()\n",
    "for line in tqdm(rubrics_list):\n",
    "    split_rubrics = line.split('_')\n",
    "    split_rubrics = split_rubrics[1:-1]\n",
    "    unique_rubrics.extend(split_rubrics)\n",
    "unique_rubrics = set(unique_rubrics)\n",
    "unique_rubrics = '\\n'.join(unique_rubrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nplus1_materials_rubric_list.txt', 'w') as fl:\n",
    "    fl.write(unique_rubrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_nplus1_materials_csv = df_nplus1_materials.to_csv()\n",
    "with open('nplus1_materials.csv', 'w') as fl:\n",
    "    fl.write(df_nplus1_materials_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nplus1 Blog #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/popular-science-repo/nplus1_blog_index.txt') as ps_index:\n",
    "    read_index = ps_index.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read through file names on YandexDisk\n",
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/crawlers/nplus1/yd_blog.txt', 'r') as yd_n:\n",
    "    yd_index = yd_n.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a483a1912b34d6aad7d4f5698e91ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_nplus1_blog = parse_metadata_nplus1(read_index, yd_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nplus1.ru/nplus1_blog/nplus1.ru-blog-2015-03-2...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/blog/2015/03/23/andromeda</td>\n",
       "      <td>2015-03-23</td>\n",
       "      <td>Непростое прошлое Андромеды</td>\n",
       "      <td></td>\n",
       "      <td>Марат Мусин</td>\n",
       "      <td>_Космос_Астрономические дневники_</td>\n",
       "      <td></td>\n",
       "      <td>Блоги</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nplus1.ru/nplus1_blog/nplus1.ru-blog-2015-03-2...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/blog/2015/03/27/trail</td>\n",
       "      <td>2015-03-27</td>\n",
       "      <td>По млечному следу</td>\n",
       "      <td></td>\n",
       "      <td>Марат Мусин</td>\n",
       "      <td>_Блоги_Астрономические дневники_</td>\n",
       "      <td></td>\n",
       "      <td>Блоги</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nplus1.ru/nplus1_blog/nplus1.ru-blog-2015-04-0...</td>\n",
       "      <td>nplus1.ru</td>\n",
       "      <td>nplus1.ru/blog/2015/04/21/founding-of-rome</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>21 апреля 753 года до нашей эры был основан Рим</td>\n",
       "      <td></td>\n",
       "      <td>Тарас Молотилин</td>\n",
       "      <td>_Блоги_Блоги_День в истории науки_</td>\n",
       "      <td></td>\n",
       "      <td>Блоги</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     source  \\\n",
       "0  nplus1.ru/nplus1_blog/nplus1.ru-blog-2015-03-2...  nplus1.ru   \n",
       "1  nplus1.ru/nplus1_blog/nplus1.ru-blog-2015-03-2...  nplus1.ru   \n",
       "2  nplus1.ru/nplus1_blog/nplus1.ru-blog-2015-04-0...  nplus1.ru   \n",
       "\n",
       "                                          url        date  \\\n",
       "0         nplus1.ru/blog/2015/03/23/andromeda  2015-03-23   \n",
       "1             nplus1.ru/blog/2015/03/27/trail  2015-03-27   \n",
       "2  nplus1.ru/blog/2015/04/21/founding-of-rome  2015-04-21   \n",
       "\n",
       "                                             title subtitle           author  \\\n",
       "0                      Непростое прошлое Андромеды               Марат Мусин   \n",
       "1                                По млечному следу               Марат Мусин   \n",
       "2  21 апреля 753 года до нашей эры был основан Рим           Тарас Молотилин   \n",
       "\n",
       "                              rubrics tags  genre  \n",
       "0   _Космос_Астрономические дневники_       Блоги  \n",
       "1    _Блоги_Астрономические дневники_       Блоги  \n",
       "2  _Блоги_Блоги_День в истории науки_       Блоги  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nplus1_blog.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b99e67a4a2f4c7cb314a4b2f7166c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_rubrics = []\n",
    "rubrics_list = df_nplus1_blogs['rubrics'].values\n",
    "rubrics_list = rubrics_list.tolist()\n",
    "for line in tqdm(rubrics_list):\n",
    "    split_rubrics = line.split('_')\n",
    "    split_rubrics = split_rubrics[1:-1]\n",
    "    unique_rubrics.extend(split_rubrics)\n",
    "unique_rubrics = set(unique_rubrics)\n",
    "unique_rubrics = '\\n'.join(unique_rubrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nplus1_blogs_rubric_list.txt', 'w') as fl:\n",
    "    fl.write(unique_rubrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nplus1_blogs_csv = df_nplus1_blog.to_csv()\n",
    "with open('nplus1_blogs.csv', 'w') as fl:\n",
    "    fl.write(df_nplus1_blogs_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProScience Parsing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4 as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_metadata_polit(file_paths: list, yandex_disk_names: list):\n",
    "    ready_df = pd.DataFrame(columns=column_names)\n",
    "    directory_index = '/home/nst/mount/data/linguistics_hse/popular-science-research/polit.ru_prosience_wget/polit.ru/'\n",
    "    #pbar = tqdm(total=len(file_paths))\n",
    "    #pbar = tqdm(total=100)\n",
    "    \n",
    "# Iterate through file_path, yd_name\n",
    "    iterable = zip(file_paths, yandex_disk_names)\n",
    "    \n",
    "    for file_path, yandex_disk_name in tqdm(iterable):\n",
    "       # pbar.update(100)\n",
    "        row = []\n",
    "        file_path = file_path[1:]\n",
    "        directory = directory_index + file_path.rstrip()\n",
    "        \n",
    "# Open text from source file\n",
    "        with open(directory) as file_:\n",
    "            source = file_.read()\n",
    "            \n",
    "    # Compile path\n",
    "        path_index_yd = 'polit.ru_proscience/proscience_news/'\n",
    "        path = path_index_yd + yandex_disk_name\n",
    "        row.append(path)\n",
    "        \n",
    "    # Add source\n",
    "        web_source = 'http://polit.ru/rubric/proscience/'\n",
    "        row.append(web_source)\n",
    "\n",
    "    # Compile url \n",
    "        re_link = re.compile('.*/polit.ru_prosience_wget\\/(.*)index\\.html')\n",
    "        link = re_link.match(directory)\n",
    "        link = link.group(1)\n",
    "        link = ''.join(link) \n",
    "        row.append(link)\n",
    "        \n",
    "        soup_article = bs.BeautifulSoup(source, 'lxml')\n",
    "        \n",
    "    # Find date\n",
    "        raw_date = soup_article.find('div', class_='date')\n",
    "        pre_date = re.search(r'.*([0-9]{2}\\s[а-я]+\\s[0-9]{4}).*', str(raw_date))\n",
    "        date = pre_date.group(1)\n",
    "        row.append(date)\n",
    "        \n",
    "        \n",
    "    # Find a title\n",
    "        head_title = soup_article.find('h1', class_='title').text\n",
    "        \n",
    "        row.append(head_title)\n",
    " \n",
    "    # Add subtitle        \n",
    "        subtitle = ''\n",
    "        row.append(subtitle)\n",
    "\n",
    "    # Find an author\n",
    "        try:    \n",
    "            author = soup_article.find('div', class_ = 'authors').text.strip()\n",
    "        except AttributeError:\n",
    "            author = ''\n",
    "        \n",
    "        row.append(author)\n",
    "\n",
    "    # Find rubrics\n",
    "        broad_rubrics = ''\n",
    "        row.append(broad_rubrics)\n",
    "        \n",
    "    # Add tags\n",
    "        rubrics = ''\n",
    "        _rubrics = soup_article.find_all('div', class_= 'tags-subject')\n",
    "        for rub_href in _rubrics:\n",
    "            rub_tag = rub_href.select('a[href]')\n",
    "            for tag in rub_tag:\n",
    "                rubrics = rubrics + '_' + tag.get_text().lower()  \n",
    "        row.append(rubrics)\n",
    "    # Add genre\n",
    "        genre = 'Новости'\n",
    "        row.append(genre)\n",
    "\n",
    "    # Compile data frame\n",
    "        ready_df = ready_df.append(pd.Series(row, index=column_names), ignore_index=True)\n",
    "\n",
    "        #pbar.close()\n",
    "    return ready_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/polit.ru_prosience_wget/proscience_index.txt') as ps_index:\n",
    "    read_index = ps_index.readlines()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read through file names on YandexDisk\n",
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/crawlers/pro_science/for articles/yd_ps_articles.txt', 'r') as yd_n:\n",
    "    yd_index = yd_n.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read-index: 1412 \n",
      "yd_index: 1411\n"
     ]
    }
   ],
   "source": [
    "print('read-index:', len(read_index), '\\nyd_index:', len(yd_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e15572d506413da3ea4abeb4b42f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-2dde1fcc1c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_ps_articles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_metadata_polit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myd_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-58e403678c4d>\u001b[0m in \u001b[0;36mparse_metadata_polit\u001b[0;34m(file_paths, yandex_disk_names)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Find an author\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mauthor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup_article\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'authors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mauthor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, name, attrs, recursive, text, **kwargs)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         criteria.\"\"\"\n\u001b[1;32m   1291\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, attrs, recursive, text, limit, **kwargs)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m     \u001b[0mfindAll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m       \u001b[0;31m# BS3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0mfindChildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m  \u001b[0;31m# BS2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_find_all\u001b[0;34m(self, name, attrs, text, limit, generator, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m         \u001b[0;31m# If it's text, make sure the text matches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNavigableString\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36msearch_tag\u001b[0;34m(self, markup_name, markup_attrs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         if ((not self.name)\n\u001b[1;32m   1659\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mcall_function_with_tag_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m             or (not markup and self._matches(markup_name, self.name))):\n\u001b[1;32m   1662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcall_function_with_tag_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_matches\u001b[0;34m(self, markup, match_against, already_tried)\u001b[0m\n\u001b[1;32m   1733\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmarkup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_against\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1736\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmatch_against\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# Inline the cache checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0msubclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0msubtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/_weakrefset.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_ps_articles = parse_metadata_polit(read_index, yd_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polit.ru_proscience/proscience_articles/articl...</td>\n",
       "      <td>http://polit.ru/rubric/proscience/</td>\n",
       "      <td>polit.ru/article/2012/10/01/ps_krill/</td>\n",
       "      <td>01 октября 2012</td>\n",
       "      <td>Антарктика: большая роль маленького криля</td>\n",
       "      <td></td>\n",
       "      <td>Екатерина  Урюпова</td>\n",
       "      <td></td>\n",
       "      <td>_биология _глобальное потепление_естественные ...</td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polit.ru_proscience/proscience_articles/articl...</td>\n",
       "      <td>http://polit.ru/rubric/proscience/</td>\n",
       "      <td>polit.ru/article/2012/10/11/ps_sc20_aleksandrov1/</td>\n",
       "      <td>11 октября 2012</td>\n",
       "      <td>Трудовая миграция: мигрируют не люди, а сети</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>_гуманитарные и социальные  науки_даниил алекс...</td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polit.ru_proscience/proscience_articles/articl...</td>\n",
       "      <td>http://polit.ru/rubric/proscience/</td>\n",
       "      <td>polit.ru/article/2012/10/12/ps_sc20_aleksandrov2/</td>\n",
       "      <td>12 октября 2012</td>\n",
       "      <td>Даниил Александров: «Крупные ученые изменяют р...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>_даниил александров_мегагранты_наука 2.0</td>\n",
       "      <td>Статьи</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  polit.ru_proscience/proscience_articles/articl...   \n",
       "1  polit.ru_proscience/proscience_articles/articl...   \n",
       "2  polit.ru_proscience/proscience_articles/articl...   \n",
       "\n",
       "                               source  \\\n",
       "0  http://polit.ru/rubric/proscience/   \n",
       "1  http://polit.ru/rubric/proscience/   \n",
       "2  http://polit.ru/rubric/proscience/   \n",
       "\n",
       "                                                 url             date  \\\n",
       "0              polit.ru/article/2012/10/01/ps_krill/  01 октября 2012   \n",
       "1  polit.ru/article/2012/10/11/ps_sc20_aleksandrov1/  11 октября 2012   \n",
       "2  polit.ru/article/2012/10/12/ps_sc20_aleksandrov2/  12 октября 2012   \n",
       "\n",
       "                                               title subtitle  \\\n",
       "0          Антарктика: большая роль маленького криля            \n",
       "1       Трудовая миграция: мигрируют не люди, а сети            \n",
       "2  Даниил Александров: «Крупные ученые изменяют р...            \n",
       "\n",
       "               author rubrics  \\\n",
       "0  Екатерина  Урюпова           \n",
       "1                               \n",
       "2                               \n",
       "\n",
       "                                                tags   genre  \n",
       "0  _биология _глобальное потепление_естественные ...  Статьи  \n",
       "1  _гуманитарные и социальные  науки_даниил алекс...  Статьи  \n",
       "2           _даниил александров_мегагранты_наука 2.0  Статьи  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_articles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_tags = []\n",
    "tags_list = df_ps_articles['tags'].values\n",
    "tags_list = tags_list.tolist()\n",
    "for line in tags_list:\n",
    "    split_tags = line.split('_')\n",
    "    split_tags = split_tags[1:]\n",
    "    unique_tags.extend(split_tags)\n",
    "unique_tags = set(unique_tags)\n",
    "unique_tags = '\\n'.join(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('proscience_articles_tag_list.txt', 'w') as fl:\n",
    "    fl.write(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps_articles.to_csv('proscience_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProScience News ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/crawlers/pro_science/for news/proscience_index_news.txt') as ps_index:\n",
    "    read_index = ps_index.readlines()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read through file names on YandexDisk\n",
    "with open('/home/nst/mount/data/linguistics_hse/popular-science-research/crawlers/pro_science/for news/yd_ps_news.txt', 'r') as yd_n:\n",
    "    yd_index = yd_n.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read-index: 3849 \n",
      "yd_index: 3849\n"
     ]
    }
   ],
   "source": [
    "print('read-index:', len(read_index), '\\nyd_index:', len(yd_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe662b2cb4a64656a4c04d66964db79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_ps_news = parse_metadata_polit(read_index, yd_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polit.ru_proscience/proscience_news/news-2012-...</td>\n",
       "      <td>http://polit.ru/rubric/proscience/</td>\n",
       "      <td>polit.ru//news/2012/09/12/ps_bacteriofag/</td>\n",
       "      <td>12 сентября 2012</td>\n",
       "      <td>Бактериофаги можно купить только в Грузии, Рос...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>_бактериофаги_биология _естественные и точные ...</td>\n",
       "      <td>Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polit.ru_proscience/proscience_news/news-2012-...</td>\n",
       "      <td>http://polit.ru/rubric/proscience/</td>\n",
       "      <td>polit.ru//news/2012/09/12/ps_brain_education/</td>\n",
       "      <td>12 сентября 2012</td>\n",
       "      <td>Исследования мозга заставляют пересмотреть под...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>_естественные и точные науки_мозг_нейробиология</td>\n",
       "      <td>Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polit.ru_proscience/proscience_news/news-2012-...</td>\n",
       "      <td>http://polit.ru/rubric/proscience/</td>\n",
       "      <td>polit.ru//news/2012/09/13/ps_parasite_tounge/</td>\n",
       "      <td>13 сентября 2012</td>\n",
       "      <td>Мокрицы-паразиты умеют превращаться в рыбьи языки</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>_биология _естественные и точные науки_паразиты</td>\n",
       "      <td>Новости</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  polit.ru_proscience/proscience_news/news-2012-...   \n",
       "1  polit.ru_proscience/proscience_news/news-2012-...   \n",
       "2  polit.ru_proscience/proscience_news/news-2012-...   \n",
       "\n",
       "                               source  \\\n",
       "0  http://polit.ru/rubric/proscience/   \n",
       "1  http://polit.ru/rubric/proscience/   \n",
       "2  http://polit.ru/rubric/proscience/   \n",
       "\n",
       "                                             url              date  \\\n",
       "0      polit.ru//news/2012/09/12/ps_bacteriofag/  12 сентября 2012   \n",
       "1  polit.ru//news/2012/09/12/ps_brain_education/  12 сентября 2012   \n",
       "2  polit.ru//news/2012/09/13/ps_parasite_tounge/  13 сентября 2012   \n",
       "\n",
       "                                               title subtitle author rubrics  \\\n",
       "0  Бактериофаги можно купить только в Грузии, Рос...                           \n",
       "1  Исследования мозга заставляют пересмотреть под...                           \n",
       "2  Мокрицы-паразиты умеют превращаться в рыбьи языки                           \n",
       "\n",
       "                                                tags    genre  \n",
       "0  _бактериофаги_биология _естественные и точные ...  Новости  \n",
       "1    _естественные и точные науки_мозг_нейробиология  Новости  \n",
       "2    _биология _естественные и точные науки_паразиты  Новости  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps_news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_tags = []\n",
    "tags_list = df_ps_news['tags'].values\n",
    "tags_list = tags_list.tolist()\n",
    "for line in tags_list:\n",
    "    split_tags = line.split('_')\n",
    "    split_tags = split_tags[1:]\n",
    "    unique_tags.extend(split_tags)\n",
    "unique_tags = set(unique_tags)\n",
    "unique_tags = '\\n'.join(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('proscience_news_tag_list.txt', 'w') as fl:\n",
    "    fl.write(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ps_news.to_csv('proscience_news.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
