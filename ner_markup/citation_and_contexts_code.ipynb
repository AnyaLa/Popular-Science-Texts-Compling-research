{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import pymorphy2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marked_path = '/home/nst/mount/data/share/yd/popular_science_texts_store/ner_markup/final_markup/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slurp(path):\n",
    "    with open(path, 'r') as file_object:\n",
    "        return file_object.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_ne(text):\n",
    "    pattern = re.compile(r'&(.*?)!&')\n",
    "    nes = re.findall(pattern, text)\n",
    "    lemmas = []\n",
    "    for ne in nes:\n",
    "        divided = ne.split()\n",
    "        lemma = [morph.parse(word)[0].normal_form for word in divided]\n",
    "        lemma = ' '.join(lemma)\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def range_ne(texts_path, top_number):\n",
    "    nes = []\n",
    "    texts = []\n",
    "    for root, dirs, files in os.walk(texts_path):\n",
    "        for file_name in files:\n",
    "            input_path = texts_path + file_name\n",
    "            marked_text = slurp(input_path)\n",
    "            texts.append(marked_text)\n",
    "    for text in tqdm(texts):\n",
    "        found_ne = extract_ne(text)\n",
    "        #print(found_ne)\n",
    "        nes.extend(found_ne)\n",
    "    ne_dict = Counter(nes)\n",
    "    ranged_ne = list(sorted(ne_dict, key = lambda x : x[1], reverse=True))\n",
    "    print(top_number, \"most cited scholars are:\\n\", ranged_ne[:top_number]) \n",
    "    return ranged_ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NE context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_1 = 'факультета МГУ под руководством профессора &Михаила Городецкого!& в'\\\n",
    "        'содружестве с коллегами из Швейцарии из Федеральной политехнической школы'\\\n",
    "        'Лозанны под руководством профессора &Тобиаса Киппенберга!& разработали метод'\n",
    "        \n",
    "text_2 = 'Она появилась как экспериментальное ответвление генеративной грамматики'\\\n",
    "         '&Н. Хомского!& и стала известна как формальная психолингвистика'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10932.16it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_texts = preprocess([text_1, text_2, text_3])\n",
    "texts = [text_1, text_2, text_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'«Русский со словарем» — очень забавная, изящная, но вполне серьезная книга. Есть книга &Максима Кронгауза!& «Русский язык на грани нервного срыва», у которой уже второе, переработанное, более полное издание. &Кронгауз!&, кстати, тоже выпускник нашего отделения.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1387.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Русский', 'со', 'словарем', 'очень', 'забавная', 'изящная', 'но', 'вполне', 'серьезная', 'книга.', 'Есть', 'книга', '&Максима', 'Кронгауза!&', 'Русский', 'язык', 'на', 'грани', 'нервного', 'срыва', 'у', 'которой', 'уже', 'второе', 'переработанное', 'более', 'полное', 'издание.', '&Кронгауз!&', 'кстати', 'тоже', 'выпускник', 'нашего', 'отделения.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Русский со словарем очень забавная изящная но ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  preprocessed_texts\n",
       "0  Русский со словарем очень забавная изящная но ..."
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess([text_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Context(\"вполне серьезная книга. Есть книга\", \"язык на грани нервного срыва\", \"книга\", \"Максима Кронгауза\"), Context(\"второе переработанное более полное издание.\", \"тоже выпускник нашего отделения.\", \"издание.\", \"Кронгауз\")]\n"
     ]
    }
   ],
   "source": [
    "class Context:\n",
    "    def __init__(self, left_context: str, right_context: str,\n",
    "                 left_word: str, word: str):\n",
    "        self.left_context = left_context\n",
    "        self.right_context = right_context\n",
    "        self.left_word = left_word\n",
    "        self.word = word\n",
    "    def __repr__(self):\n",
    "        return 'Context(\"%s\", \"%s\", \"%s\", \"%s\")' % (\n",
    "            self.left_context, self.right_context,\n",
    "            self.left_word, self.word)\n",
    "\n",
    "def tokenize_text(text: str) -> [str]:\n",
    "    return re.findall(r'&?[\\w.\\'-]+!?&?', text, flags=re.UNICODE)\n",
    "\n",
    "def cleanup_tag(text: str) -> str:\n",
    "    return text.replace('&', '').replace('!', '')\n",
    "\n",
    "def get_span(tokens: [str], start: int, end: int) -> str:\n",
    "    return cleanup_tag(' '.join(tokens[start:end]))\n",
    "\n",
    "def get_complete_word(index: int, tokens: [str]) -> (str, int, bool):\n",
    "    current_word = tokens[index]\n",
    "    if not current_word.startswith('&'):\n",
    "        return current_word, index+1, False\n",
    "\n",
    "    word_parts = [current_word]\n",
    "    index += 1\n",
    "    if not current_word.endswith('!&'):\n",
    "        while index < len(tokens):\n",
    "            current_word = tokens[index]\n",
    "            word_parts.append(current_word)\n",
    "            if current_word.endswith('!&'):\n",
    "                index += 1\n",
    "                break\n",
    "            index += 1\n",
    "        else:\n",
    "            raise ValueError('No matching closing tag in tokens: \"%s\"' % tokens)\n",
    "    \n",
    "    word = cleanup_tag(' '.join(word_parts))\n",
    "    return word, index, True\n",
    "\n",
    "assert ('a', 1, False) == get_complete_word(0, ['a', 'b'])\n",
    "assert ('b', 2, False) == get_complete_word(1, ['a', 'b'])\n",
    "assert ('a', 1, True) == get_complete_word(0, ['&a!&', 'b']), get_complete_word(0, ['&a!&', 'b'])\n",
    "assert ('a b', 2, True) == get_complete_word(0, ['&a', 'b!&'])\n",
    "assert ('a b c', 3, True) == get_complete_word(0, ['&a', 'b', 'c!&'])\n",
    "\n",
    "def extract_contexts(text: str, window_size: int) -> [Context]:\n",
    "    result = []\n",
    "    \n",
    "    tokens = tokenize_text(text)\n",
    "    index = 0\n",
    "\n",
    "    while index < len(tokens):\n",
    "        word, new_index, is_tag = get_complete_word(index, tokens)\n",
    "        if not is_tag:\n",
    "            index = new_index\n",
    "            continue\n",
    "\n",
    "        left_context = get_span(tokens, index-5, index)\n",
    "        right_context = get_span(tokens, new_index+1, new_index+6)\n",
    "        left_word = get_span(tokens, index-1, index)\n",
    "        \n",
    "        context = Context(left_context, right_context, left_word, word)\n",
    "        result.append(context)\n",
    "        \n",
    "        index = new_index\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(extract_contexts(text_3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    #pattern = re.compile(r'[\\w.-]+')\n",
    "    clean_texts = []\n",
    "    for text in tqdm(texts):\n",
    "        split_text = re.findall(r'&?[\\w.\\'-]+!?&?', text, flags=re.UNICODE)\n",
    "        print(split_text)\n",
    "        joined_text = ' '.join(split_text)\n",
    "        clean_texts.append(joined_text)\n",
    "    #print(clean_texts)\n",
    "    preproc_texts = pd.DataFrame(clean_texts, columns=['preprocessed_texts'])\n",
    "    return preproc_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'&(.*?)!&')\n",
    "nes = re.finditer(pattern, text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 107\n",
      "208 219\n"
     ]
    }
   ],
   "source": [
    "find_names = re.finditer(pattern, text_3)\n",
    "#print(find_names)\n",
    "for name in list(find_names):\n",
    "    start, end = name.span()\n",
    "    print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_entities_indices(clean_text, marked_text):\n",
    "    indices = []\n",
    "    entity_index_left = None\n",
    "    entity_index_right = None\n",
    "    pattern = re.compile(r'&(.*?)!&')\n",
    "    nes = re.finditer(pattern, marked_text)\n",
    "   # print(nes)\n",
    "    for name in nes:\n",
    "        name = name.split()\n",
    "        if len(name)==1:\n",
    "            name = ''.join(name)\n",
    "            try:\n",
    "                entity_index_left = clean_text.index(name)\n",
    "            except ValueError:\n",
    "                print('Name:', name)\n",
    "                print('Text_marked:', marked_text)\n",
    "                raise \n",
    "            try:\n",
    "                entity_index_right = clean_text.index(name) + len(name) \n",
    "            except ValueError:\n",
    "                print('Name:', name)\n",
    "                print('Text_marked:', marked_text)\n",
    "                raise                             \n",
    "        else:\n",
    "            try:\n",
    "                entity_index_left = clean_text.index(name[0])\n",
    "            except ValueError:\n",
    "                print('Name:', name[0])\n",
    "                print('Text_marked:', marked_text)\n",
    "                raise \n",
    "            try:\n",
    "                entity_index_right = clean_text.index(name[-1]) + len(name[-1])\n",
    "            except ValueError:\n",
    "                print('Name:', name[0])\n",
    "                print('Text_marked:', marked_text)\n",
    "                raise \n",
    "        index_pair = (entity_index_left, entity_index_right)\n",
    "        indices.append(index_pair)\n",
    "    return indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_3 = '«Русский со словарем» — очень забавная, изящная, но вполне серьезная книга. Есть книга &Максима Кронгауза!& «Русский язык на грани нервного срыва», у которой уже второе, переработанное, более полное издание. &Кронгауз!&, кстати, тоже выпускник нашего отделения.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'«Русский со словарем» — очень забавная, изящная, но вполне серьезная книга. Есть книга &Максима Кронгауза!& «Русский язык на грани нервного срыва», у которой уже второе, переработанное, более полное издание. &Кронгауз!&, кстати, тоже выпускник нашего отделения.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_sre.SRE_Match' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d0229f7d2fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_entities_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-111-b04f2f742ec8>\u001b[0m in \u001b[0;36mextract_entities_indices\u001b[0;34m(clean_text, marked_text)\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0;31m# print(nes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_sre.SRE_Match' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "indices = extract_entities_indices(preprocessed_texts.preprocessed_texts[2], texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(81, 98), (89, 97)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'аксима К'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_3[89:97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_context(clean_text, entities_indices, window):\n",
    "    left = []\n",
    "    names = []\n",
    "    right = []\n",
    "    for index_pair in entities_indices:\n",
    "        left_index = index_pair[0]\n",
    "        right_index = index_pair[1] + 1\n",
    "        name = clean_text[left_index:right_index]\n",
    "        names.append(name)\n",
    "        left_context = clean_text[:left_index].split()\n",
    "        if len(left_context) < window:\n",
    "            left_context = clean_text[:left_index]\n",
    "        else:\n",
    "            left_context = ' '.join(left_context[-window:])\n",
    "        left.append(left_context)    \n",
    "        right_context = clean_text[right_index:].split()\n",
    "        if len(right_context) < window:\n",
    "            right_context = clean_text[right_index:]\n",
    "        else:\n",
    "            right_context = ' '.join(right_context[:window+1])\n",
    "        right.append(right_context)\n",
    "    return left, names, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['как экспериментальное ответвление генеративной грамматики'],\n",
       " ['Н. Хомского '],\n",
       " ['и стала известна как формальная психолингвистика'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_context(preprocessed_texts.preprocessed_texts[1], indices, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_contexts(clean_texts, marked_texts, window):\n",
    "    indices_list = [extract_entities_indices(clean_text, marked_text)\n",
    "              for clean_text, marked_text in zip(clean_texts, marked_texts)]\n",
    "    lefts_list = []\n",
    "    names_list = []\n",
    "    rights_list = []\n",
    "    for text, indices in zip(clean_texts, indices_list):\n",
    "        left, names, right = get_context(text, indices, window)\n",
    "        lefts_list.extend(left)\n",
    "        names_list.extend(names)\n",
    "        rights_list.extend(right)\n",
    "    dataframe = pd.DataFrame(lefts_list, columns=['left_context'])\n",
    "    dataframe['named_entities'] = names_list\n",
    "    dataframe['right_context'] = rights_list\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataframe and get all NE contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marked & Preprocessed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_texts_df(texts_path):\n",
    "    marked_texts = []\n",
    "    for root, dirs, files in os.walk(texts_path):\n",
    "        for file_name in files:\n",
    "            input_path = texts_path + file_name\n",
    "            marked_text = slurp(input_path)\n",
    "            marked_texts.append(marked_text)\n",
    "    marked_df = pd.DataFrame(marked_texts, columns=['marked_texts'])\n",
    "    return marked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marked_df = make_texts_df(marked_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 750.44it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_texts = preprocess(marked_df.marked_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_df = marked_df.join(preprocessed_texts) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_df.preprocessed_texts[2] ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all contexts from marked texts with window 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contexts_df = get_all_contexts(texts_df.preprocessed_texts, texts_df.marked_texts, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1903"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_duplicates = contexts_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_context</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>right_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Из выступления лауреата Нобелевской премии</td>\n",
       "      <td>Ричарда Фейнмана</td>\n",
       "      <td>в Калифорнийском технологическом институте в 1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>проблема была в 1981 году</td>\n",
       "      <td>Гердом Биннигом</td>\n",
       "      <td>и Генрихом Рорером сотрудниками швейцарского о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981 году Гердом Биннигом и</td>\n",
       "      <td>Генрихом Рорером</td>\n",
       "      <td>сотрудниками швейцарского отделения IBM сконст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>сотрудниками IBM Almaden Research Center</td>\n",
       "      <td>Дональдом Эйглером</td>\n",
       "      <td>и Эрхардом Швейцером в 1990 году</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Research Center Дональдом Эйглером и</td>\n",
       "      <td>Эрхардом Швейцером</td>\n",
       "      <td>в 1990 году заключался в том</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 left_context       named_entities  \\\n",
       "0  Из выступления лауреата Нобелевской премии    Ричарда Фейнмана    \n",
       "1                   проблема была в 1981 году     Гердом Биннигом    \n",
       "2                 1981 году Гердом Биннигом и    Генрихом Рорером    \n",
       "3    сотрудниками IBM Almaden Research Center  Дональдом Эйглером    \n",
       "4        Research Center Дональдом Эйглером и  Эрхардом Швейцером    \n",
       "\n",
       "                                       right_context  \n",
       "0  в Калифорнийском технологическом институте в 1959  \n",
       "1  и Генрихом Рорером сотрудниками швейцарского о...  \n",
       "2  сотрудниками швейцарского отделения IBM сконст...  \n",
       "3                   и Эрхардом Швейцером в 1990 году  \n",
       "4                       в 1990 году заключался в том  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_duplicates = remove_duplicates.reset_index(drop=True)\n",
    "remove_duplicates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_duplicates.to_csv('contexts_draft.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.txt\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(marked_path):\n",
    "    for file_name in files:\n",
    "        input_path = marked_path + file_name\n",
    "        marked_text = slurp(input_path)\n",
    "        if 'Кронгауз' in marked_text:\n",
    "            print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Когда &Гарри Уиттингтон!& и его ученики &Дерек Бриггс!& и &Саймон Конвей Моррис!&'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Когда &Гарри Уиттингтон!& и его ученики &Дерек Бриггс!& и &Саймон Конвей Моррис!&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/nst/mount/data/linguistics_hse/popular-science-research/popular-science-repo/Popular-Science-Texts-Compling-research/ner_markup/contexts_draft.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>left_context</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>right_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Из выступления лауреата Нобелевской премии</td>\n",
       "      <td>Ричарда Фейнмана</td>\n",
       "      <td>в Калифорнийском технологическом институте в 1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>проблема была в 1981 году</td>\n",
       "      <td>Гердом Биннигом</td>\n",
       "      <td>и Генрихом Рорером сотрудниками швейцарского о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1981 году Гердом Биннигом и</td>\n",
       "      <td>Генрихом Рорером</td>\n",
       "      <td>сотрудниками швейцарского отделения IBM сконст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>сотрудниками IBM Almaden Research Center</td>\n",
       "      <td>Дональдом Эйглером</td>\n",
       "      <td>и Эрхардом Швейцером в 1990 году</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Research Center Дональдом Эйглером и</td>\n",
       "      <td>Эрхардом Швейцером</td>\n",
       "      <td>в 1990 году заключался в том</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>подобная работа была проделана группой</td>\n",
       "      <td>Джозефа Стросцио</td>\n",
       "      <td>из Национального Института Стандартов и Технол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>сотрудниками IBM Almaden Research Center</td>\n",
       "      <td>Дональдом Эйглеро</td>\n",
       "      <td>м и Эрхардом Швейцером в 1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>этом больше всех писал академик</td>\n",
       "      <td>Андрей Анатольевич Зализняк</td>\n",
       "      <td>. Дело в том что написать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>лингвистике. Это прежде всего книга</td>\n",
       "      <td>Зализняка</td>\n",
       "      <td>Из заметок о любительской лингвистике книга</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>заметок о любительской лингвистике книга</td>\n",
       "      <td>Ирины Левонтиной</td>\n",
       "      <td>Русский со словарем очень забавная изящная</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>вполне серьезная книга. Есть книга</td>\n",
       "      <td>Максима Кронгауза</td>\n",
       "      <td>Русский язык на грани нервного срыва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>серьезная книга. Есть книга Максима</td>\n",
       "      <td>Кронгауза</td>\n",
       "      <td>Русский язык на грани нервного срыва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>учебник под редакцией Михаила Викторовича</td>\n",
       "      <td>Панова</td>\n",
       "      <td>. Но в школьном образовании русский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>это не так и на</td>\n",
       "      <td>Маркса</td>\n",
       "      <td>мы не ссылаемся и безыдейный структурализм</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>вам Ньютона разрешают изучать а</td>\n",
       "      <td>Эйнштейна</td>\n",
       "      <td>уже нет. Что кстати и пытались</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>. Это было при ректоре</td>\n",
       "      <td>Логунове</td>\n",
       "      <td>что его не красит совершенно. Не</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>всех писал академик Андрей Анатольевич</td>\n",
       "      <td>Зализняк</td>\n",
       "      <td>. Дело в том что написать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>объектов можно назвать тогдашнюю аспирантку</td>\n",
       "      <td>Джоселин Белл</td>\n",
       "      <td>и ее руководителя Энтони Хьюиша .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Джоселин Белл и ее руководителя</td>\n",
       "      <td>Энтони Хьюиша</td>\n",
       "      <td>. Причем понимание того с источниками</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Белл и ее руководителя Энтони</td>\n",
       "      <td>Хьюиша</td>\n",
       "      <td>. Причем понимание того с источниками</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1974 году за это открытие</td>\n",
       "      <td>Э. Хьюишу</td>\n",
       "      <td>была присуждена Нобелевская премия по физике.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>отмечал 90-летие со дня рождения</td>\n",
       "      <td>Ричарда Ф. Фейнмана</td>\n",
       "      <td>. Помимо того что он нобелевский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>со дня рождения Ричарда Ф.</td>\n",
       "      <td>Фейнмана</td>\n",
       "      <td>. Помимо того что он нобелевский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>комбинациях. Вот например таблица у</td>\n",
       "      <td>Менделеева</td>\n",
       "      <td>он понял что множество совершенно разных</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>все это любопытно. Вот когда</td>\n",
       "      <td>Максвелл</td>\n",
       "      <td>в XIX веке открыл что электричество</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>и есть гравитация. Две силы.</td>\n",
       "      <td>Эйнштейн</td>\n",
       "      <td>пытался их все время объединить и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>палеонтолога и специалист по трилобитам</td>\n",
       "      <td>Ричарда Форти</td>\n",
       "      <td>. Автор рассказывает о важнейшей эпохе</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>и специалист по трилобитам Ричарда</td>\n",
       "      <td>Форти</td>\n",
       "      <td>. Автор рассказывает о важнейшей эпохе</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>древнейших ископаемых - трилобитов. Когда</td>\n",
       "      <td>Гарри Уиттингтон</td>\n",
       "      <td>и его ученики Дерек Бриггс и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Гарри Уиттингтон и его ученики</td>\n",
       "      <td>Дерек Бриггс</td>\n",
       "      <td>и Саймон Конвей Моррис теперь они</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>в области медицины. ИТ медик</td>\n",
       "      <td>Мажуга Александр Георгиевич</td>\n",
       "      <td>Подробнее о научной деятельности Профессия будет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1226</td>\n",
       "      <td>приводить в пример даже вездесущего</td>\n",
       "      <td>Леонардо да Винчи</td>\n",
       "      <td>. Попыток стремлений было много а</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1227</td>\n",
       "      <td>первый настоящий искусственный интеллект сказал</td>\n",
       "      <td>Эрик Сигель</td>\n",
       "      <td>доктор философии лектор и просветитель в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1228</td>\n",
       "      <td>Профессор математики из Оксфордского университета</td>\n",
       "      <td>Роджер Пенроуз</td>\n",
       "      <td>высказывается против этой теории Некоторые из</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1229</td>\n",
       "      <td>МТИ под руководством пионера робототехники</td>\n",
       "      <td>Родни Брукса</td>\n",
       "      <td>японка начала разрабатывать кисть и руку</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1230</td>\n",
       "      <td>под руководством пионера робототехники Родни</td>\n",
       "      <td>Брукса</td>\n",
       "      <td>японка начала разрабатывать кисть и руку</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>мудро и остроумно выразился ученый</td>\n",
       "      <td>С.К. Далсгард</td>\n",
       "      <td>S.C. Dalsgaard из университета в Оденсе</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1232</td>\n",
       "      <td>остроумно выразился ученый С.К. Далсгард</td>\n",
       "      <td>S.C. Dalsgaard</td>\n",
       "      <td>из университета в Оденсе имеющий отношение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1233</td>\n",
       "      <td>через это но бесценные труды</td>\n",
       "      <td>Гордона Холта</td>\n",
       "      <td>J. Gordon Holt направили меня по</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1234</td>\n",
       "      <td>но бесценные труды Гордона Холта</td>\n",
       "      <td>J. Gordon Holt</td>\n",
       "      <td>направили меня по правильному пути. Что</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1235</td>\n",
       "      <td>изображена молекулярная структура льда созданная</td>\n",
       "      <td>Масакацу Мацумото</td>\n",
       "      <td>. Красные шарики атомы кислорода. Голубые</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>1236</td>\n",
       "      <td>быть забавной Обучение через музыку</td>\n",
       "      <td>Альберт Эйнштейн</td>\n",
       "      <td>рассказывал репортерам что он часто рассуждает</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>1237</td>\n",
       "      <td>забавной Обучение через музыку Альберт</td>\n",
       "      <td>Эйнштейн</td>\n",
       "      <td>рассказывал репортерам что он часто рассуждает</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1238</td>\n",
       "      <td>начинает со ссылки на исследования</td>\n",
       "      <td>Флойда Тула</td>\n",
       "      <td>Floyd Toole своего бывшего коллеги и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1239</td>\n",
       "      <td>ссылки на исследования Флойда Тула</td>\n",
       "      <td>Floyd Toole</td>\n",
       "      <td>своего бывшего коллеги и Шона Олива</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>1240</td>\n",
       "      <td>Toole своего бывшего коллеги и</td>\n",
       "      <td>Шона Олива</td>\n",
       "      <td>Sean Olive уже нынешнего коллеги в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1241</td>\n",
       "      <td>бывшего коллеги и Шона Олива</td>\n",
       "      <td>Sean Olive</td>\n",
       "      <td>уже нынешнего коллеги в Harman которые</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>1242</td>\n",
       "      <td>начинает со ссылки на исследования</td>\n",
       "      <td>Флойда Тула</td>\n",
       "      <td>Floyd Toole своего бывшего коллеги и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1243</td>\n",
       "      <td>Toole своего бывшего коллеги и</td>\n",
       "      <td>Шона Олива</td>\n",
       "      <td>Sean Olive уже нынешнего коллеги в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>1244</td>\n",
       "      <td>это разница которую можно расслышать</td>\n",
       "      <td>Чтобы</td>\n",
       "      <td>это выяснить я измерил частотные характеристики</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1245</td>\n",
       "      <td>проигрывателе восходит не к фонографу</td>\n",
       "      <td>Томаса Эдисона</td>\n",
       "      <td>представленному в 1877 году а к</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1246</td>\n",
       "      <td>1877 году а к граммофону</td>\n",
       "      <td>Эмиля Берлинера</td>\n",
       "      <td>Emile Berliner изобретенному в 1887 году.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1247</td>\n",
       "      <td>а к граммофону Эмиля Берлинера</td>\n",
       "      <td>Emile Berliner</td>\n",
       "      <td>изобретенному в 1887 году. Первые грампластинки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>году а к граммофону Эмиля</td>\n",
       "      <td>Берлинера</td>\n",
       "      <td>Emile Berliner изобретенному в 1887 году.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1249</td>\n",
       "      <td>запись на немецком языке созданная</td>\n",
       "      <td>Берлинером</td>\n",
       "      <td>в Ганновере 11 ноября 1889 года.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>1250</td>\n",
       "      <td>году а к граммофону Эмиля</td>\n",
       "      <td>Берлинера</td>\n",
       "      <td>Emile Berliner изобретенному в 1887 году.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1251</td>\n",
       "      <td>могли прослушать запись. Вместе со</td>\n",
       "      <td>Стефаном Пуилле</td>\n",
       "      <td>Stephan Puille коллегой Патрика ученые выяснили</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>1252</td>\n",
       "      <td>запись. Вместе со Стефаном Пуилле</td>\n",
       "      <td>Stephan Puille</td>\n",
       "      <td>коллегой Патрика ученые выяснили что 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1253</td>\n",
       "      <td>проигрывателе восходит не к фонографу</td>\n",
       "      <td>Томаса Эдисона представленному в 1877 году а к...</td>\n",
       "      <td>Курс лекций натурфилософии и механических иску...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1254</td>\n",
       "      <td>Совсем недавно мы рассказывали о</td>\n",
       "      <td>Патрике Фистере</td>\n",
       "      <td>и его истории об архивной находке</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                       left_context  \\\n",
       "0              0         Из выступления лауреата Нобелевской премии   \n",
       "1              1                          проблема была в 1981 году   \n",
       "2              2                        1981 году Гердом Биннигом и   \n",
       "3              3           сотрудниками IBM Almaden Research Center   \n",
       "4              4               Research Center Дональдом Эйглером и   \n",
       "5              5             подобная работа была проделана группой   \n",
       "6              6           сотрудниками IBM Almaden Research Center   \n",
       "7              7                    этом больше всех писал академик   \n",
       "8              8                лингвистике. Это прежде всего книга   \n",
       "9              9           заметок о любительской лингвистике книга   \n",
       "10            10                 вполне серьезная книга. Есть книга   \n",
       "11            11                серьезная книга. Есть книга Максима   \n",
       "12            12          учебник под редакцией Михаила Викторовича   \n",
       "13            13                                    это не так и на   \n",
       "14            14                    вам Ньютона разрешают изучать а   \n",
       "15            15                             . Это было при ректоре   \n",
       "16            16             всех писал академик Андрей Анатольевич   \n",
       "17            17        объектов можно назвать тогдашнюю аспирантку   \n",
       "18            18                    Джоселин Белл и ее руководителя   \n",
       "19            19                      Белл и ее руководителя Энтони   \n",
       "20            20                          1974 году за это открытие   \n",
       "21            21                   отмечал 90-летие со дня рождения   \n",
       "22            22                         со дня рождения Ричарда Ф.   \n",
       "23            23                комбинациях. Вот например таблица у   \n",
       "24            24                       все это любопытно. Вот когда   \n",
       "25            25                       и есть гравитация. Две силы.   \n",
       "26            26            палеонтолога и специалист по трилобитам   \n",
       "27            27                 и специалист по трилобитам Ричарда   \n",
       "28            28          древнейших ископаемых - трилобитов. Когда   \n",
       "29            29                     Гарри Уиттингтон и его ученики   \n",
       "...          ...                                                ...   \n",
       "1225        1225                       в области медицины. ИТ медик   \n",
       "1226        1226                приводить в пример даже вездесущего   \n",
       "1227        1227    первый настоящий искусственный интеллект сказал   \n",
       "1228        1228  Профессор математики из Оксфордского университета   \n",
       "1229        1229         МТИ под руководством пионера робототехники   \n",
       "1230        1230       под руководством пионера робототехники Родни   \n",
       "1231        1231                 мудро и остроумно выразился ученый   \n",
       "1232        1232           остроумно выразился ученый С.К. Далсгард   \n",
       "1233        1233                       через это но бесценные труды   \n",
       "1234        1234                   но бесценные труды Гордона Холта   \n",
       "1235        1235   изображена молекулярная структура льда созданная   \n",
       "1236        1236                быть забавной Обучение через музыку   \n",
       "1237        1237             забавной Обучение через музыку Альберт   \n",
       "1238        1238                 начинает со ссылки на исследования   \n",
       "1239        1239                 ссылки на исследования Флойда Тула   \n",
       "1240        1240                     Toole своего бывшего коллеги и   \n",
       "1241        1241                       бывшего коллеги и Шона Олива   \n",
       "1242        1242                 начинает со ссылки на исследования   \n",
       "1243        1243                     Toole своего бывшего коллеги и   \n",
       "1244        1244               это разница которую можно расслышать   \n",
       "1245        1245              проигрывателе восходит не к фонографу   \n",
       "1246        1246                           1877 году а к граммофону   \n",
       "1247        1247                     а к граммофону Эмиля Берлинера   \n",
       "1248        1248                          году а к граммофону Эмиля   \n",
       "1249        1249                 запись на немецком языке созданная   \n",
       "1250        1250                          году а к граммофону Эмиля   \n",
       "1251        1251                 могли прослушать запись. Вместе со   \n",
       "1252        1252                  запись. Вместе со Стефаном Пуилле   \n",
       "1253        1253              проигрывателе восходит не к фонографу   \n",
       "1254        1254                   Совсем недавно мы рассказывали о   \n",
       "\n",
       "                                         named_entities  \\\n",
       "0                                     Ричарда Фейнмана    \n",
       "1                                      Гердом Биннигом    \n",
       "2                                     Генрихом Рорером    \n",
       "3                                   Дональдом Эйглером    \n",
       "4                                   Эрхардом Швейцером    \n",
       "5                                     Джозефа Стросцио    \n",
       "6                                     Дональдом Эйглеро   \n",
       "7                          Андрей Анатольевич Зализняк    \n",
       "8                                            Зализняка    \n",
       "9                                     Ирины Левонтиной    \n",
       "10                                   Максима Кронгауза    \n",
       "11                                            Кронгауза   \n",
       "12                                              Панова    \n",
       "13                                              Маркса    \n",
       "14                                           Эйнштейна    \n",
       "15                                            Логунове    \n",
       "16                                            Зализняк    \n",
       "17                                       Джоселин Белл    \n",
       "18                                       Энтони Хьюиша    \n",
       "19                                               Хьюиша   \n",
       "20                                           Э. Хьюишу    \n",
       "21                                 Ричарда Ф. Фейнмана    \n",
       "22                                             Фейнмана   \n",
       "23                                          Менделеева    \n",
       "24                                            Максвелл    \n",
       "25                                            Эйнштейн    \n",
       "26                                       Ричарда Форти    \n",
       "27                                               Форти    \n",
       "28                                    Гарри Уиттингтон    \n",
       "29                                        Дерек Бриггс    \n",
       "...                                                 ...   \n",
       "1225                       Мажуга Александр Георгиевич    \n",
       "1226                                 Леонардо да Винчи    \n",
       "1227                                       Эрик Сигель    \n",
       "1228                                    Роджер Пенроуз    \n",
       "1229                                      Родни Брукса    \n",
       "1230                                            Брукса    \n",
       "1231                                     С.К. Далсгард    \n",
       "1232                                    S.C. Dalsgaard    \n",
       "1233                                     Гордона Холта    \n",
       "1234                                    J. Gordon Holt    \n",
       "1235                                 Масакацу Мацумото    \n",
       "1236                                  Альберт Эйнштейн    \n",
       "1237                                          Эйнштейн    \n",
       "1238                                       Флойда Тула    \n",
       "1239                                       Floyd Toole    \n",
       "1240                                        Шона Олива    \n",
       "1241                                        Sean Olive    \n",
       "1242                                        Флойда Тула   \n",
       "1243                                         Шона Олива   \n",
       "1244                                             Чтобы    \n",
       "1245                                    Томаса Эдисона    \n",
       "1246                                   Эмиля Берлинера    \n",
       "1247                                    Emile Berliner    \n",
       "1248                                         Берлинера    \n",
       "1249                                        Берлинером    \n",
       "1250                                          Берлинера   \n",
       "1251                                   Стефаном Пуилле    \n",
       "1252                                    Stephan Puille    \n",
       "1253  Томаса Эдисона представленному в 1877 году а к...   \n",
       "1254                                   Патрике Фистере    \n",
       "\n",
       "                                          right_context  \n",
       "0     в Калифорнийском технологическом институте в 1959  \n",
       "1     и Генрихом Рорером сотрудниками швейцарского о...  \n",
       "2     сотрудниками швейцарского отделения IBM сконст...  \n",
       "3                      и Эрхардом Швейцером в 1990 году  \n",
       "4                          в 1990 году заключался в том  \n",
       "5     из Национального Института Стандартов и Технол...  \n",
       "6                         м и Эрхардом Швейцером в 1990  \n",
       "7                             . Дело в том что написать  \n",
       "8           Из заметок о любительской лингвистике книга  \n",
       "9            Русский со словарем очень забавная изящная  \n",
       "10                 Русский язык на грани нервного срыва  \n",
       "11                 Русский язык на грани нервного срыва  \n",
       "12                  . Но в школьном образовании русский  \n",
       "13           мы не ссылаемся и безыдейный структурализм  \n",
       "14                       уже нет. Что кстати и пытались  \n",
       "15                     что его не красит совершенно. Не  \n",
       "16                            . Дело в том что написать  \n",
       "17                    и ее руководителя Энтони Хьюиша .  \n",
       "18                . Причем понимание того с источниками  \n",
       "19                . Причем понимание того с источниками  \n",
       "20        была присуждена Нобелевская премия по физике.  \n",
       "21                     . Помимо того что он нобелевский  \n",
       "22                     . Помимо того что он нобелевский  \n",
       "23             он понял что множество совершенно разных  \n",
       "24                  в XIX веке открыл что электричество  \n",
       "25                    пытался их все время объединить и  \n",
       "26               . Автор рассказывает о важнейшей эпохе  \n",
       "27               . Автор рассказывает о важнейшей эпохе  \n",
       "28                         и его ученики Дерек Бриггс и  \n",
       "29                    и Саймон Конвей Моррис теперь они  \n",
       "...                                                 ...  \n",
       "1225   Подробнее о научной деятельности Профессия будет  \n",
       "1226                  . Попыток стремлений было много а  \n",
       "1227           доктор философии лектор и просветитель в  \n",
       "1228      высказывается против этой теории Некоторые из  \n",
       "1229           японка начала разрабатывать кисть и руку  \n",
       "1230           японка начала разрабатывать кисть и руку  \n",
       "1231            S.C. Dalsgaard из университета в Оденсе  \n",
       "1232         из университета в Оденсе имеющий отношение  \n",
       "1233                   J. Gordon Holt направили меня по  \n",
       "1234            направили меня по правильному пути. Что  \n",
       "1235          . Красные шарики атомы кислорода. Голубые  \n",
       "1236     рассказывал репортерам что он часто рассуждает  \n",
       "1237     рассказывал репортерам что он часто рассуждает  \n",
       "1238               Floyd Toole своего бывшего коллеги и  \n",
       "1239                своего бывшего коллеги и Шона Олива  \n",
       "1240                 Sean Olive уже нынешнего коллеги в  \n",
       "1241             уже нынешнего коллеги в Harman которые  \n",
       "1242               Floyd Toole своего бывшего коллеги и  \n",
       "1243                 Sean Olive уже нынешнего коллеги в  \n",
       "1244    это выяснить я измерил частотные характеристики  \n",
       "1245                    представленному в 1877 году а к  \n",
       "1246          Emile Berliner изобретенному в 1887 году.  \n",
       "1247    изобретенному в 1887 году. Первые грампластинки  \n",
       "1248          Emile Berliner изобретенному в 1887 году.  \n",
       "1249                   в Ганновере 11 ноября 1889 года.  \n",
       "1250          Emile Berliner изобретенному в 1887 году.  \n",
       "1251    Stephan Puille коллегой Патрика ученые выяснили  \n",
       "1252            коллегой Патрика ученые выяснили что 11  \n",
       "1253  Курс лекций натурфилософии и механических иску...  \n",
       "1254                  и его истории об архивной находке  \n",
       "\n",
       "[1255 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count most frequent collocations in contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    preproc_texts = []\n",
    "    pattern = re.compile(r'\\w+')\n",
    "    try:\n",
    "        for text in tqdm(texts):\n",
    "            text = text.lower()\n",
    "            words = ' '.join(re.findall(pattern, text))\n",
    "            preproc_texts.append(words)\n",
    "    except AttributeError:\n",
    "        print('Corrupted:', text)\n",
    "        preproc_texts.append('')\n",
    "    return preproc_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [00:00<00:00, 93385.95it/s]\n",
      "100%|██████████| 1216/1216 [00:00<00:00, 93964.03it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_left = preprocess(df.left_context)\n",
    "preprocessed_right = preprocess(df.right_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1216"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=0, how='any')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>из выступления лауреата нобелевской премии</td>\n",
       "      <td>в калифорнийском технологическом институте в 1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>проблема была в 1981 году</td>\n",
       "      <td>и генрихом рорером сотрудниками швейцарского о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981 году гердом биннигом и</td>\n",
       "      <td>сотрудниками швейцарского отделения ibm сконст...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         left  \\\n",
       "0  из выступления лауреата нобелевской премии   \n",
       "1                   проблема была в 1981 году   \n",
       "2                 1981 году гердом биннигом и   \n",
       "\n",
       "                                               right  \n",
       "0  в калифорнийском технологическом институте в 1959  \n",
       "1  и генрихом рорером сотрудниками швейцарского о...  \n",
       "2  сотрудниками швейцарского отделения ibm сконст...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = pd.DataFrame(preprocessed_left, columns=['left'])\n",
    "preprocessed_df['right'] = preprocessed_right\n",
    "preprocessed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_tokens_list(texts):\n",
    "    tokens = []\n",
    "    for text in texts:\n",
    "        text = text.split()\n",
    "    tokens.extend(text)\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_left = compile_tokens_list(preprocessed_df.left)\n",
    "tokens_right = compile_tokens_list(preprocessed_df.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aprior_probability(dictionary):\n",
    "    s = sum(dictionary.values())\n",
    "    for word  in dictionary:\n",
    "        dictionary[word] /= s\n",
    "   # aprior_dictionary = dict(wiki_freq).get(word)/s\n",
    "    return dict(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigram_probability(bigrams):\n",
    "    count_bigrams = len(bigrams)\n",
    "    joined_bigrams = [' '.join(bigram) for bigram in bigrams]\n",
    "    bigrams_dict = Counter(joined_bigrams)\n",
    "    for bigram in bigrams_dict:\n",
    "        bigrams_dict[bigram] /= count_bigrams\n",
    "    return dict(bigrams_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_pmi(bigrams, bigrams_prob, words_aprior):\n",
    "    joined_bigrams = []\n",
    "    pmis = []\n",
    "    for bigram in bigrams:\n",
    "        #print(bigram)\n",
    "        joined_bigram = ' '.join(bigram)\n",
    "        pmi = math.log(bigrams_prob.get(joined_bigram)/\n",
    "                      (words_aprior.get(bigram[0])*words_aprior.get(bigram[1])))\n",
    "        joined_bigrams.append(joined_bigram)\n",
    "        pmis.append(pmi)\n",
    "    counted_pmi = list(zip(joined_bigrams, pmis))\n",
    "    return counted_pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def range_pmi(pmis_list, top_k):\n",
    "    pmis_dict = dict(pmis_list)\n",
    "    best_pmis = sorted(pmis_dict, key = lambda x:x[1], reverse = True)\n",
    "    print(best_pmis[:top_k])\n",
    "    return best_pmis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_collocations(tokens, top_best):\n",
    "    freq = Counter(tokens.split())\n",
    "    bigrams = list(nltk.bigrams(tokens.split()))\n",
    "    aprior = aprior_probability(freq)\n",
    "    bigrams_prob = bigram_probability(bigrams)\n",
    "    pmi = count_pmi(bigrams, bigrams_prob, aprior)\n",
    "    best = range_pmi(pmi, top_best)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['мы рассказывали', 'совсем недавно', 'недавно мы', 'рассказывали о']\n"
     ]
    }
   ],
   "source": [
    "# top best left \n",
    "collocations_left = extract_collocations(tokens_left, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['истории об', 'архивной находке', 'его истории', 'об архивной', 'и его']\n"
     ]
    }
   ],
   "source": [
    "# top best right\n",
    "collocations_right = extract_collocations(tokens_right, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210     соотечественником Виталием Гинзбургом и америк...\n",
       "211     интервью рассказывает доктор психологических наук\n",
       "212          годов которые проводили выдающиеся археологи\n",
       "213            выдающиеся археологи Артемий Арциховский и\n",
       "214            Впрочем позже другие археологи петербуржец\n",
       "215                      культ которого установил на Руси\n",
       "216                                  . Однако в 1939 году\n",
       "217                        1939 году Владимир Богусевич и\n",
       "218                      рубрике Как получить Нобелевку .\n",
       "219                     И со стипендией которая позволила\n",
       "220            нобелиата началась с Джей-Джея знаменитого\n",
       "222                     получить Нобелевку . Оуэн Уилланс\n",
       "223             с другими студентами будущими нобелиатами\n",
       "224     студентами будущими нобелиатами Эрнестом Резер...\n",
       "225     Резерфордом Чарльзом Вильсоном будущим доктора...\n",
       "227                         потом и любовником Марии Кюри\n",
       "228                 с Джей-Джея знаменитого Джозефа Джона\n",
       "229                       быть точнее на платиновых. Идея\n",
       "230                        одна вышла замуж за математика\n",
       "231                вторая за ассистента Ричардсона физика\n",
       "232                      половине XX века станет академик\n",
       "233                      только по термионике. Как только\n",
       "234     поверхности освещенной ультрафиолетом проверяя...\n",
       "235             с другими студентами будущими нобелиатами\n",
       "236     студентами будущими нобелиатами Эрнестом Резер...\n",
       "237                   специалисте по физике твердого тела\n",
       "238               лонг-лист премии Просветитель есть труд\n",
       "239                   аппаратуры мне очень нравится фраза\n",
       "240                        ничего не изменилось со времен\n",
       "242                  зоне просвещения очень важна подача.\n",
       "                              ...                        \n",
       "1225                         в области медицины. ИТ медик\n",
       "1226                  приводить в пример даже вездесущего\n",
       "1227      первый настоящий искусственный интеллект сказал\n",
       "1228    Профессор математики из Оксфордского университета\n",
       "1229           МТИ под руководством пионера робототехники\n",
       "1230         под руководством пионера робототехники Родни\n",
       "1231                   мудро и остроумно выразился ученый\n",
       "1232             остроумно выразился ученый С.К. Далсгард\n",
       "1233                         через это но бесценные труды\n",
       "1234                     но бесценные труды Гордона Холта\n",
       "1235     изображена молекулярная структура льда созданная\n",
       "1236                  быть забавной Обучение через музыку\n",
       "1237               забавной Обучение через музыку Альберт\n",
       "1238                   начинает со ссылки на исследования\n",
       "1239                   ссылки на исследования Флойда Тула\n",
       "1240                       Toole своего бывшего коллеги и\n",
       "1241                         бывшего коллеги и Шона Олива\n",
       "1242                   начинает со ссылки на исследования\n",
       "1243                       Toole своего бывшего коллеги и\n",
       "1244                 это разница которую можно расслышать\n",
       "1245                проигрывателе восходит не к фонографу\n",
       "1246                             1877 году а к граммофону\n",
       "1247                       а к граммофону Эмиля Берлинера\n",
       "1248                            году а к граммофону Эмиля\n",
       "1249                   запись на немецком языке созданная\n",
       "1250                            году а к граммофону Эмиля\n",
       "1251                   могли прослушать запись. Вместе со\n",
       "1252                    запись. Вместе со Стефаном Пуилле\n",
       "1253                проигрывателе восходит не к фонографу\n",
       "1254                     Совсем недавно мы рассказывали о\n",
       "Name: left_context, Length: 1016, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.left_context[200:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
