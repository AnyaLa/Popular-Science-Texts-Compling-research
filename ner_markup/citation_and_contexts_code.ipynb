{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import pymorphy2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marked_path = '/home/nst/mount/data/share/yd/popular_science_texts_store/ner_markup/final_markup/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slurp(path):\n",
    "    with open(path, 'r') as file_object:\n",
    "        return file_object.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_ne(text):\n",
    "    pattern = re.compile(r'&(.*?)!&')\n",
    "    nes = re.findall(pattern, text)\n",
    "    lemmas = []\n",
    "    for ne in nes:\n",
    "        divided = ne.split()\n",
    "        lemma = [morph.parse(word)[0].normal_form for word in divided]\n",
    "        lemma = ' '.join(lemma)\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def range_ne(texts_path, top_number):\n",
    "    nes = []\n",
    "    texts = []\n",
    "    for root, dirs, files in os.walk(texts_path):\n",
    "        for file_name in files:\n",
    "            input_path = texts_path + file_name\n",
    "            marked_text = slurp(input_path)\n",
    "            texts.append(marked_text)\n",
    "    for text in tqdm(texts):\n",
    "        found_ne = extract_ne(text)\n",
    "        #print(found_ne)\n",
    "        nes.extend(found_ne)\n",
    "    ne_dict = Counter(nes)\n",
    "    ranged_ne = list(sorted(ne_dict, key = lambda x : x[1], reverse=True))\n",
    "    print(top_number, \"most cited scholars are:\\n\", ranged_ne[:top_number]) \n",
    "    return ranged_ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NE context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    #pattern = re.compile(r'[\\w.-]+')\n",
    "    clean_texts = []\n",
    "    for text in tqdm(texts):\n",
    "        split_text = re.findall(r'[\\w.\\'-]+', text, flags=re.UNICODE)\n",
    "        joined_text = ' '.join(split_text)\n",
    "        clean_texts.append(joined_text)\n",
    "    preproc_texts = pd.DataFrame(clean_texts, columns=['preprocessed_texts'])\n",
    "    return preproc_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_entities_indices(clean_text, marked_text):\n",
    "    indices = []\n",
    "    entity_index_left = None\n",
    "    entity_index_right = None\n",
    "    pattern = re.compile(r'&(.*?)!&')\n",
    "    nes = re.findall(pattern, marked_text)\n",
    "   # print(nes)\n",
    "    for name in nes:\n",
    "        name = name.split()\n",
    "        if len(name)==1:\n",
    "            name = ''.join(name)\n",
    "            try:\n",
    "                entity_index_left = clean_text.index(name)\n",
    "            except ValueError:\n",
    "                print('Name:', name)\n",
    "                print('Text_marked:', marked_text)\n",
    "                raise \n",
    "            try:\n",
    "                entity_index_right = clean_text.index(name) + len(name) \n",
    "            except ValueError:\n",
    "                print('Name:', name)\n",
    "                print('Text_marked:', marked_text)\n",
    "                raise                             \n",
    "        else:\n",
    "            try:\n",
    "                entity_index_left = clean_text.index(name[0])\n",
    "            except ValueError:\n",
    "                print('Name:', name[0])\n",
    "                print('Text_marked:', marked_text)\n",
    "                raise \n",
    "            try:\n",
    "                entity_index_right = clean_text.index(name[-1]) + len(name[-1])\n",
    "            except ValueError:\n",
    "                print('Name:', name[0])\n",
    "                print('Text_marked:', marked_text)\n",
    "                raise \n",
    "        index_pair = (entity_index_left, entity_index_right)\n",
    "        indices.append(index_pair)\n",
    "    return indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_context(clean_text, entities_indices, window):\n",
    "    left = []\n",
    "    names = []\n",
    "    right = []\n",
    "    for index_pair in entities_indices:\n",
    "        left_index = index_pair[0]\n",
    "        right_index = index_pair[1] + 1\n",
    "        name = clean_text[left_index:right_index]\n",
    "        names.append(name)\n",
    "        left_context = clean_text[:left_index].split()\n",
    "        if len(left_context) < window:\n",
    "            left_context = clean_text[:left_index]\n",
    "        else:\n",
    "            left_context = ' '.join(left_context[-window:])\n",
    "        left.append(left_context)    \n",
    "        right_context = clean_text[right_index:].split()\n",
    "        if len(right_context) < window:\n",
    "            right_context = clean_text[right_index:]\n",
    "        else:\n",
    "            right_context = ' '.join(right_context[:window+1])\n",
    "        right.append(right_context)\n",
    "    return left, names, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_contexts(clean_texts, marked_texts, window):\n",
    "    indices_list = [extract_entities_indices(clean_text, marked_text)\n",
    "              for clean_text, marked_text in zip(clean_texts, marked_texts)]\n",
    "    lefts_list = []\n",
    "    names_list = []\n",
    "    rights_list = []\n",
    "    for text, indices in zip(clean_texts, indices_list):\n",
    "        left, names, right = get_context(text, indices, window)\n",
    "        lefts_list.extend(left)\n",
    "        names_list.extend(names)\n",
    "        rights_list.extend(right)\n",
    "    dataframe = pd.DataFrame(lefts_list, columns=['left_context'])\n",
    "    dataframe['named_entities'] = names_list\n",
    "    dataframe['right_context'] = rights_list\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataframe and get all NE contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marked & Preprocessed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_texts_df(texts_path):\n",
    "    marked_texts = []\n",
    "    for root, dirs, files in os.walk(texts_path):\n",
    "        for file_name in files:\n",
    "            input_path = texts_path + file_name\n",
    "            marked_text = slurp(input_path)\n",
    "            marked_texts.append(marked_text)\n",
    "    marked_df = pd.DataFrame(marked_texts, columns=['marked_texts'])\n",
    "    return marked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marked_df = make_texts_df(marked_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 750.44it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_texts = preprocess(marked_df.marked_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_df = marked_df.join(preprocessed_texts) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df.preprocessed_texts[2] ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all contexts from marked texts with window 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts_df = get_all_contexts(texts_df.preprocessed_texts, texts_df.marked_texts, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1903"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_duplicates = contexts_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-4031b19e757d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mremove_duplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mremove_duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "remove_duplicates = remove_duplicates.reset_index()\n",
    "remove_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_audiomania_blog_251144.txt\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(marked_path):\n",
    "    for file_name in files:\n",
    "        input_path = marked_path + file_name\n",
    "        marked_text = slurp(input_path)\n",
    "        if 'Субдискретизация' in marked_text:\n",
    "            print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Когда &Гарри Уиттингтон!& и его ученики &Дерек Бриггс!& и &Саймон Конвей Моррис!&'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Когда &Гарри Уиттингтон!& и его ученики &Дерек Бриггс!& и &Саймон Конвей Моррис!&'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
