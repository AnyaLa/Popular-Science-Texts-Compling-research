{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_texts_root = r'/home/nst/mount/data/share/yd/'\\\n",
    "                   'popular_science_texts_store/ner_markup/test_ner/test_texts/'\n",
    "    \n",
    "output_root = r'/home/nst/mount/data/share/yd/'\\\n",
    "               'popular_science_texts_store/ner_markup/test_ner/output_texts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'nplus1.ru-news-2015-05-10-darkenergy.txt'\n",
    "sample_path_in = test_texts_root + file_name\n",
    "sample_path_out = output_root + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slurp(path):\n",
    "    with open(path, 'r') as file_object:\n",
    "        return file_object.read()\n",
    "    \n",
    "def spit(path, text):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'w') as file_object:\n",
    "        return file_object.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = slurp(sample_path_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5021"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spit(sample_path_out, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assertEqual(a, b):\n",
    "    if a != b:\n",
    "        raise AssertionError('expected \"%s\", actual \"%s\"' % (a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_tags(text, index_start, index_end):\n",
    "    initial_tag = '<>'\n",
    "    final_tag = '</>'\n",
    "    return text[:index_start] + initial_tag + text[index_start:index_end] \\\n",
    "        + final_tag + text[index_end:]\n",
    "\n",
    "assertEqual('ученый <>Хокинг</>', \n",
    "           insert_tags('ученый Хокинг', 7, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_text(text):\n",
    "    pattern = re.compile(r'([А-ЯЁ][а-яё]+|[A-Z][a-z]+)')\n",
    "    find_ner = re.finditer(pattern, text)\n",
    "    for item in reversed(list(find_ner)):\n",
    "        start_index, end_index = item.span()\n",
    "        text = insert_tags(text, start_index, end_index)\n",
    "    return text\n",
    "\n",
    "assertEqual('ученый <>Хокинг</> из <>Великобритании</>', \n",
    "           tag_text('ученый Хокинг из Великобритании'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_capitals(text):\n",
    "    \"\"\"\n",
    "    Makes a list of words in caplitals\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'([А-ЯЁ][а-яё]+|[A-Z][a-z]+)')\n",
    "    find_capitals = re.finditer(pattern, text)\n",
    "    capitals = [match.group() for match in find_capitals] \n",
    "    return capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_capitals_list(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Creates a list of potential names\n",
    "    \"\"\"\n",
    "    capitals = []\n",
    "    texts = []\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for file_name in files:\n",
    "            file_path = input_path + file_name\n",
    "            text = slurp(file_path)\n",
    "            texts.append(text)\n",
    "    for text in texts:\n",
    "        words = extract_capitals(text)\n",
    "        capitals.extend(words)\n",
    "    capitals = set(capitals)\n",
    "    file_object = open(output_path, 'w')\n",
    "    for word in capitals:\n",
    "        file_object.write(\"%s\\n\" % word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_path = '/home/nst/mount/data/share/yd/popular_science_texts_store/'\\\n",
    "'ner_markup/test_ner/test_texts/'\n",
    "list_output = '/home/nst/mount/data/share/yd/popular_science_texts_store/ner_markup/capitals.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_capitals_list(texts_path, list_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(list_output, 'r') as fo:\n",
    "    capitals = fo.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10667"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(capitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtext import KeywordProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if keyword_processor.extract_keywords(word) == [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "libre_dict = slurp('/home/nst/mount/data/share/yd/comp_ling/spell-check/russian-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "libre_dict = libre_dict.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = KeywordProcessor()\n",
    "processor.add_keywords_from_list(libre_dict.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['дома', 'н', 'й']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.extract_keywords('домашний')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_common_words(list_output_path):\n",
    "    potential_names = []\n",
    "    with open(list_output_path, 'r') as fo:\n",
    "        capitals = fo.readlines()\n",
    "    for word in capitals:\n",
    "        word = word.lower()\n",
    "        word = word.rstrip()\n",
    "        if not processor.extract_keywords(word) == [word]:\n",
    "            potential_names.append(word)\n",
    "    potential_names = set(potential_names)\n",
    "    file_object = open(list_output_path, 'w')\n",
    "    for word in potential_names:\n",
    "        file_object.write(\"%s\\n\" % word)\n",
    "    print('Deleted common words, current size:', len(potential_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted common words, current size: 9625\n"
     ]
    }
   ],
   "source": [
    "delete_common_words(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make draft files ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(test_texts_root):\n",
    "    for file_name in files:\n",
    "        input_path = test_texts_root + file_name\n",
    "        output_path = output_root + file_name[:-3] + 'xml'\n",
    "        text = tag_text(slurp(input_path))\n",
    "        spit(output_path, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draft_texts_root = r'/home/nst/mount/data/share/yd/'\\\n",
    "               'popular_science_texts_store/ner_markup/test_ner/output_texts/'\n",
    "    \n",
    "final_texts_root = r'/home/nst/mount/data/share/yd/popular_science_texts_store/'\\\n",
    "                'ner_markup/final_markup/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_tags(marked_texts_root):\n",
    "    start_tag = '<>'\n",
    "    final_tag = '</>'\n",
    "    for root, dirs, files in os.walk(marked_texts_root):\n",
    "        for file_name in files:\n",
    "            file_path = draft_texts_root + file_name\n",
    "            content = slurp(file_path)\n",
    "            marked_text = re.sub(start_tag, '&', content)\n",
    "            marked_text = re.sub(final_tag, '!&', marked_text)\n",
    "            output_path = final_texts_root + file_name[:-3] + 'txt'\n",
    "            spit(output_path, marked_text)\n",
    "    print('I\\'m done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make final changes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm done\n"
     ]
    }
   ],
   "source": [
    "change_tags(draft_texts_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
