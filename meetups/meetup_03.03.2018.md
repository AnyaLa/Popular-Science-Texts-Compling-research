## Уютный разговор 03.03.2018
## Имена ученых
- Посмотреть в разметку друг друга. 
- Проблема лемматизации имен.
- Составляем конкорданс (окно 5 слов). закинуть код + результаты на гитхаб.
- Просмотреть контексты.
- Теги частей речи для контекстов. Составляем словарь контекстных терминов.
- Ограниченный набор правил.

Этапы:
- контексты
- насколько разнообразны
- искать решение (свой код питон, либо машинное обучение)

Лемматизация имен:
- С помощью расстояния Левенштейна. Если расстояние между словами маленькое, то объединяем их в группу. В группе выделяется главное слово. 
- Сколько групп имен? Составить словарь. 
- Open Linked Data. Wiki Data (Sql-подобные запросы на Sparql). Можно брать все словоформы из списка и спрашивать знает ли WikiData слово из словаря (если делать автоматически). 

## Термины

- Посмотреть ресурсы Arzamas и indicator, попробовать вытащить оттуда предразмеченные редакторами термины;
- Вытащить термины из размеченных текстов в формате KWIC (окно 5); 
- изучить контекст употребления и особенности конструкций:
    1. Если конструкции однотипные и простые, составить словарь терминов, написать правила (код на питоне);
    2. Если конструкции разнообразны и сложны, написать грамматику для TOMITA Parser;
    3. Если случаи совсем сложные, использовать методы машинного обучения, подумать какие для этого нужно использовать фичи

## Тематическое моделирование

1. Построить матрицу попарной  похожести текстов по разным метрикам (попробовать doc2vec, Jaccard similarity, Locality-sensitive hashing), затем по матрице строить графы с помощью NetworkX и igraph. По матрице должна быть возможность достать конкретные примеры похожих/не похожих текстов.
2. Если расчеты по большому объему текстов выполняются очень долго: свой код оптимизировать, поискать другие реализации в модулях питона, либо попробовать методы на тестовом множестве, затем можно будет запустить на всех текстах на сервере
3. Расписать задачи по неделям

## Ридабилити
1. Выложить на гит код для подсчета предложений, слов и слогов, даже в "непричесанном" виде.
2. Связаться с авторами LeStCor (если не получится -- попробовать самостоятельно восстановить результаты их деятельности)
3. Создать размеченный корпус текстов. Мы выделяем 3 класса сложности: базовый, сложный, очень сложный. Подумать, можно ли добавить в эти тексты еще какие-то элементы для разметки. Тексты 1 категории можно взять из н+1 и блогов.
4. Разбить существующий план на временные отрезки